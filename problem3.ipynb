{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To copy this template: File -> Save a Copy in Drive\n",
        "\n",
        "***DISCLAIMER**: In case of any discrepancy in the assignment instruction, please refer to the `PDF` document.*"
      ],
      "metadata": {
        "id": "OMAdi9qgC-B9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3 - Which Algorithm is Better?"
      ],
      "metadata": {
        "id": "NcDhlfqyBd6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1"
      ],
      "metadata": {
        "id": "-id00ye6CNLB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "Retrieval Algorithm 1:\n",
        "\n",
        "|   | Actual <br> Positive  | Actual <br> Negative  |\n",
        "|:---:|:---:|:---:|\n",
        "| **Predicted <br> Positive** | 25 | 15 |\n",
        "| **Predicted <br> Negative** | 5  | 55 |\n",
        "\n",
        "Retrieval Algorithm 2:\n",
        "\n",
        "|   | Actual <br> Positive  | Actual <br> Negative  |\n",
        "|:---:|:---:|:---:|\n",
        "| **Predicted <br> Positive** | 20 | 10 |\n",
        "| **Predicted <br> Negative** | 10 | 60 |\n",
        "\n"
      ],
      "metadata": {
        "id": "4kineJbrfcg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algorithm 1:\n",
        "\n",
        "Total Positive Samples: 30 (25 TP + 5 FN)\n",
        "\n",
        "Total Negative Samples: 70 (15 FP + 55 TN)\n",
        "\n",
        "Balanced Accuracy = (Sensitivity + Specificity) / 2\n",
        "\n",
        "Sensitivity = TP / (TP + FN) = 25 / (25 + 5) = 0.8333\n",
        "\n",
        "Specificity = TN / (TN + FP) = 55 / (55 + 15) = 0.7857\n",
        "\n",
        "Balanced Accuracy = (0.8333 + 0.7857) / 2 ≈ 0.8095\n",
        "\n",
        "Accuracy = (TP + TN) / Total Samples = (25 + 55) / 100 = 0.80\n",
        "\n",
        "Precision  = TP / (TP + FP) = 25 / (25 + 15) = 0.625\n",
        "\n",
        "Recall = TP / (TP + FN) = 25 / (25 + 5) = 0.8333\n",
        "\n",
        "\n",
        "F1-Score  = 2 * (Precision * Recall) / (Precision + Recall) = 2 * (0.625 * 0.8333) / (0.625 + 0.8333) ≈ 0.7143"
      ],
      "metadata": {
        "id": "GcmQojQPsLNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algorithm 2:\n",
        "\n",
        "Total Positive Samples: 30 (20 TP + 10 FN)\n",
        "\n",
        "Total Negative Samples: 70 (10 FP + 60 TN)\n",
        "\n",
        "Sensitivity = TP / (TP + FN) = 20 / (20 + 10) = 0.6667\n",
        "\n",
        "Specificity  = TN / (TN + FP) = 60 / (60 + 10) = 0.8571\n",
        "\n",
        "Balnced Accuracy = (0.6667 + 0.8571) / 2 ≈ 0.7619\n",
        "\n",
        "Accuracy = (TP + TN) / Total Samples = (20 + 60) / 100 = 0.80\n",
        "\n",
        "Precision= TP / (TP + FP) = 20 / (20 + 10) = 0.6667\n",
        "\n",
        "Recall = TP / (TP + FN) = 20 / (20 + 10) = 0.6667\n",
        "\n",
        "F1-Score = 2 * (Precision * Recall) / (Precision + Recall) = 2 * (0.6667 * 0.6667) / (0.6667 + 0.6667) = 0.6667\n",
        "\n"
      ],
      "metadata": {
        "id": "nSKFukUbyziM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2"
      ],
      "metadata": {
        "id": "e1D_yfneCWqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "If you are looking to see which model performs better on negative classes your friend is correct. Balanced accuracy equally considers negative and postive by averaging sensitivity and specificity, whereas F1 mostly focuses on the postive class. The negative class is more indirectly factored into this with the use of precision and recall. Algorithm 1 has a balanced accuracy score of 0.8 compared to 0.76 of Algorithm 2."
      ],
      "metadata": {
        "id": "BX8Ns_Imf-BI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3"
      ],
      "metadata": {
        "id": "TpMHZDOECjD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "Both of their advice was not helpful in identifying the correct model. Algorithm 1 had a better F1 score and a balanced accuracy but Algorithm 2 is the correct model."
      ],
      "metadata": {
        "id": "GRo9fm0tf-ga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4"
      ],
      "metadata": {
        "id": "YdDLYruzClXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "I think that specificity is the best metric to make this decision. Algorithm 1 has a specificity of 0.786 versus 0.857 for algorithm 2."
      ],
      "metadata": {
        "id": "RdaMp6ZBf_DF"
      }
    }
  ]
}